{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-30T20:52:24.499960Z","iopub.execute_input":"2022-08-30T20:52:24.500348Z","iopub.status.idle":"2022-08-30T20:52:24.531354Z","shell.execute_reply.started":"2022-08-30T20:52:24.500247Z","shell.execute_reply":"2022-08-30T20:52:24.530535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport seaborn as sns\n\nfrom random import randint\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:52:24.533009Z","iopub.execute_input":"2022-08-30T20:52:24.533632Z","iopub.status.idle":"2022-08-30T20:52:25.548784Z","shell.execute_reply.started":"2022-08-30T20:52:24.533598Z","shell.execute_reply":"2022-08-30T20:52:25.547576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:52:25.550772Z","iopub.execute_input":"2022-08-30T20:52:25.551114Z","iopub.status.idle":"2022-08-30T20:52:25.591180Z","shell.execute_reply.started":"2022-08-30T20:52:25.551084Z","shell.execute_reply":"2022-08-30T20:52:25.590130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"age - Age of the patient\n\nsex - Sex of the patient\n\ncp - Chest pain type ~ 0 = Typical Angina, 1 = Atypical Angina, 2 = Non-anginal Pain, 3 = Asymptomatic\n\ntrtbps - Resting blood pressure (in mm Hg)\n\nchol - Cholestoral in mg/dl fetched via BMI sensor\n\nfbs - (fasting blood sugar > 120 mg/dl) ~ 1 = True, 0 = False\n\nrestecg - Resting electrocardiographic results ~ 0 = Normal, 1 = ST-T wave normality, 2 = Left ventricular hypertrophy\n\nthalachh - Maximum heart rate achieved\n\noldpeak - Previous peak\n\nslp - Slope\n\ncaa - Number of major vessels\n\nthall - Thalium Stress Test result ~ (0,3)\n\nexng - Exercise induced angina ~ 1 = Yes, 0 = No\n\noutput - Target variable. 0= less chance of heart attack 1= more chance of heart attack\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:31:23.119739Z","iopub.execute_input":"2022-08-30T20:31:23.120179Z","iopub.status.idle":"2022-08-30T20:31:23.130572Z","shell.execute_reply.started":"2022-08-30T20:31:23.120132Z","shell.execute_reply":"2022-08-30T20:31:23.128818Z"}}},{"cell_type":"code","source":"print(\"The shape of the dataset is:\", df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:52:30.194237Z","iopub.execute_input":"2022-08-30T20:52:30.195069Z","iopub.status.idle":"2022-08-30T20:52:30.200868Z","shell.execute_reply.started":"2022-08-30T20:52:30.195029Z","shell.execute_reply":"2022-08-30T20:52:30.199840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:52:36.990179Z","iopub.execute_input":"2022-08-30T20:52:36.991212Z","iopub.status.idle":"2022-08-30T20:52:37.006257Z","shell.execute_reply.started":"2022-08-30T20:52:36.991176Z","shell.execute_reply":"2022-08-30T20:52:37.005404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:52:39.828425Z","iopub.execute_input":"2022-08-30T20:52:39.829085Z","iopub.status.idle":"2022-08-30T20:52:39.852353Z","shell.execute_reply.started":"2022-08-30T20:52:39.829046Z","shell.execute_reply":"2022-08-30T20:52:39.851573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seperating the columns into continous, categorical and the target \ncategorical_columns = ['sex','exng','caa','cp','fbs','restecg','slp','thall']\ncontinuous_columns = [\"age\",\"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]\ntarget_columns = [\"output\"]\nprint(\"The categorial cols are : \", categorical_columns)\nprint(\"The continuous cols are : \", continuous_columns)\nprint(\"The target variable is :  \", target_columns)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:53:18.187147Z","iopub.execute_input":"2022-08-30T20:53:18.187548Z","iopub.status.idle":"2022-08-30T20:53:18.194653Z","shell.execute_reply.started":"2022-08-30T20:53:18.187518Z","shell.execute_reply":"2022-08-30T20:53:18.193481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Summary Statistics\ndf[continuous_columns].describe()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:53:27.207212Z","iopub.execute_input":"2022-08-30T20:53:27.208241Z","iopub.status.idle":"2022-08-30T20:53:27.234672Z","shell.execute_reply.started":"2022-08-30T20:53:27.208200Z","shell.execute_reply":"2022-08-30T20:53:27.233863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:53:28.678004Z","iopub.execute_input":"2022-08-30T20:53:28.678436Z","iopub.status.idle":"2022-08-30T20:53:28.687408Z","shell.execute_reply.started":"2022-08-30T20:53:28.678400Z","shell.execute_reply":"2022-08-30T20:53:28.686629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It clearly shows that there are no Nan values","metadata":{}},{"cell_type":"markdown","source":"## Univariate Analysis","metadata":{}},{"cell_type":"code","source":"# Count plot for categorical Data\ndef plot_countplot(variable):\n    colors = list(mcolors.CSS4_COLORS.keys())\n    plt.figure(figsize = (9,3))\n    sns.countplot(df[variable], palette= \"tab10\", color = colors[randint(0, len(colors))], edgecolor = \"black\")\n    plt.xlabel(variable, color = \"w\", fontsize = 20)\n    plt.ylabel(\"Frequency\", color = \"w\", fontsize = 20)\n    plt.title(f\"{variable} | Distribution with Countplot\", color = \"w\", fontsize = 20)\n    plt.grid(True, axis = \"y\")\n    plt.show()\n\nfor n in categorical_columns:\n    plot_countplot(n)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:53:37.066662Z","iopub.execute_input":"2022-08-30T20:53:37.067059Z","iopub.status.idle":"2022-08-30T20:53:38.144053Z","shell.execute_reply.started":"2022-08-30T20:53:37.067025Z","shell.execute_reply":"2022-08-30T20:53:38.142596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxen plot for categorical Data\ndef plot_boxenplot(variable):\n    colors = list(mcolors.CSS4_COLORS.keys())\n    plt.figure(figsize = (9,3))\n    sns.boxenplot(df[variable], color = colors[randint(0, len(colors))])\n    plt.xlabel(variable, color = \"w\", fontsize = 20)\n    plt.ylabel(\"Frequency\", color = \"w\", fontsize = 20)\n    plt.title(f\"{variable} | Distribution with BoxenPlot\", color = \"w\", fontsize = 20)\n    plt.grid(True, axis = \"x\")\n    plt.show()\n\nfor n in continuous_columns:\n    plot_boxenplot(n)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:53:38.955152Z","iopub.execute_input":"2022-08-30T20:53:38.955584Z","iopub.status.idle":"2022-08-30T20:53:39.839529Z","shell.execute_reply.started":"2022-08-30T20:53:38.955548Z","shell.execute_reply":"2022-08-30T20:53:39.838547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count Plot for the target variable\n# labels = \"Low Chance of having a Heart Attack\", \"High Chance of having a heart attack\"\ndef plot_countplot(variable):\n    colors = list(mcolors.CSS4_COLORS.keys())\n    plt.figure(figsize = (9,3))\n    sns.countplot(df[variable], palette= \"tab10\", color = colors[randint(0, len(colors))], edgecolor = \"black\")\n    plt.xlabel(variable, color = \"w\", fontsize = 20)\n    plt.ylabel(\"Frequency\", color = \"w\", fontsize = 20)\n    plt.title(f\"{variable} | Distribution with Countplot\", color = \"w\", fontsize = 20)\n    plt.grid(True, axis = \"y\")\n    plt.show()\n\nfor n in target_columns:\n    plot_countplot(n)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:53:43.033182Z","iopub.execute_input":"2022-08-30T20:53:43.034029Z","iopub.status.idle":"2022-08-30T20:53:43.218773Z","shell.execute_reply.started":"2022-08-30T20:53:43.033989Z","shell.execute_reply":"2022-08-30T20:53:43.217699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:54:16.806844Z","iopub.execute_input":"2022-08-30T20:54:16.807263Z","iopub.status.idle":"2022-08-30T20:54:16.834463Z","shell.execute_reply.started":"2022-08-30T20:54:16.807227Z","shell.execute_reply":"2022-08-30T20:54:16.833087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8)) \nsns.heatmap(df[continuous_columns].corr(),annot=True,linewidths = 2, cmap = \"coolwarm\")\n            \nplt.title(\"Correlation Table\", fontweight = \"bold\", color = \"w\")\nplt.xticks(rotation=45, color = \"w\")\nplt.yticks(rotation=45, color = \"w\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:54:18.276882Z","iopub.execute_input":"2022-08-30T20:54:18.277739Z","iopub.status.idle":"2022-08-30T20:54:18.633696Z","shell.execute_reply.started":"2022-08-30T20:54:18.277691Z","shell.execute_reply":"2022-08-30T20:54:18.632374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,12))\ncorr_mat = df.corr().stack().reset_index(name=\"correlation\")\ng = sns.relplot(\n    data=corr_mat,\n    x=\"level_0\", y=\"level_1\", hue=\"correlation\", size=\"correlation\",\n    palette=\"YlGnBu\", hue_norm=(-1, 1), edgecolor=\".7\",\n    height=10, sizes=(50, 250), size_norm=(-.2, .8),\n)\ng.set(xlabel=\"features on X\", ylabel=\"featurs on Y\", aspect=\"equal\")\ng.fig.suptitle('Scatterplot heatmap',fontsize=20, fontweight='bold', fontfamily='serif', color=\"#000000\")\ng.despine(left=True, bottom=True)\ng.ax.margins(.02)\nfor label in g.ax.get_xticklabels():\n    label.set_rotation(90)\nfor artist in g.legend.legendHandles:\n    artist.set_edgecolor(\".7\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:54:21.136397Z","iopub.execute_input":"2022-08-30T20:54:21.137550Z","iopub.status.idle":"2022-08-30T20:54:21.872212Z","shell.execute_reply.started":"2022-08-30T20:54:21.137496Z","shell.execute_reply":"2022-08-30T20:54:21.871346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,18))\ngs = fig.add_gridspec(5,2)\ngs.update(wspace=0.5, hspace=0.5)\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[1,0])\nax3 = fig.add_subplot(gs[1,1])\nax4 = fig.add_subplot(gs[2,0])\nax5 = fig.add_subplot(gs[2,1])\nax6 = fig.add_subplot(gs[3,0])\nax7 = fig.add_subplot(gs[3,1])\nax8 = fig.add_subplot(gs[4,0])\nax9 = fig.add_subplot(gs[4,1])\n\nbackground_color = \"#bbe6e6\"\ncolor_palette = [\"#805000\",\"#8000af\",\"#6aac90\",\"#5833ff\",\"#da8829\"]\nfig.patch.set_facecolor(background_color) \nax0.set_facecolor(background_color) \nax1.set_facecolor(background_color) \nax2.set_facecolor(background_color)\nax3.set_facecolor(background_color)\nax4.set_facecolor(background_color)\nax5.set_facecolor(background_color) \nax6.set_facecolor(background_color) \nax7.set_facecolor(background_color)\nax8.set_facecolor(background_color)\nax9.set_facecolor(background_color)\n\n# Age title\nax0.text(0.5,0.5,\"Distribution of age\\naccording to\\n target variable\\n\",\n        horizontalalignment = 'center',\n        verticalalignment = 'center',\n        fontsize = 18,\n        fontweight='bold',\n        fontfamily='serif',\n        color='#000000')\nax0.spines[\"bottom\"].set_visible(False)\nax0.set_xticklabels([])\nax0.set_yticklabels([])\nax0.tick_params(left=False, bottom=False)\n\n# Age\nax1.grid(color='#000000', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nsns.kdeplot(ax=ax1, data=df, x='age',hue=\"output\", fill=True,palette=[\"#8000ff\",\"#da8829\"], alpha=.5, linewidth=0)\nax1.set_xlabel(\"\")\nax1.set_ylabel(\"\")\n\n# TrTbps title\nax2.text(0.5,0.5,\"Distribution of trtbps\\naccording to\\n target variable\\n\",\n        horizontalalignment = 'center',\n        verticalalignment = 'center',\n        fontsize = 18,\n        fontweight='bold',\n        fontfamily='serif',\n        color='#000000')\nax2.spines[\"bottom\"].set_visible(False)\nax2.set_xticklabels([])\nax2.set_yticklabels([])\nax2.tick_params(left=False, bottom=False)\n\n# TrTbps\nax3.grid(color='#000000', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nsns.kdeplot(ax=ax3, data=df, x='trtbps',hue=\"output\", fill=True,palette=[\"#8000ff\",\"#da8829\"], alpha=.5, linewidth=0)\nax3.set_xlabel(\"\")\nax3.set_ylabel(\"\")\n\n# Chol title\nax4.text(0.5,0.5,\"Distribution of chol\\naccording to\\n target variable\\n\",\n        horizontalalignment = 'center',\n        verticalalignment = 'center',\n        fontsize = 18,\n        fontweight='bold',\n        fontfamily='serif',\n        color='#000000')\nax4.spines[\"bottom\"].set_visible(False)\nax4.set_xticklabels([])\nax4.set_yticklabels([])\nax4.tick_params(left=False, bottom=False)\n\n# Chol\nax5.grid(color='#000000', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nsns.kdeplot(ax=ax5, data=df, x='chol',hue=\"output\", fill=True,palette=[\"#8000ff\",\"#da8829\"], alpha=.5, linewidth=0)\nax5.set_xlabel(\"\")\nax5.set_ylabel(\"\")\n\n# Thalachh title\nax6.text(0.5,0.5,\"Distribution of thalachh\\naccording to\\n target variable\\n\",\n        horizontalalignment = 'center',\n        verticalalignment = 'center',\n        fontsize = 18,\n        fontweight='bold',\n        fontfamily='serif',\n        color='#000000')\nax6.spines[\"bottom\"].set_visible(False)\nax6.set_xticklabels([])\nax6.set_yticklabels([])\nax6.tick_params(left=False, bottom=False)\n\n# Thalachh\nax7.grid(color='#000000', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nsns.kdeplot(ax=ax7, data=df, x='thalachh',hue=\"output\", fill=True,palette=[\"#8000ff\",\"#da8829\"], alpha=.5, linewidth=0)\nax7.set_xlabel(\"\")\nax7.set_ylabel(\"\")\n\n# Oldpeak title\nax8.text(0.5,0.5,\"Distribution of oldpeak\\naccording to\\n target variable\\n\",\n        horizontalalignment = 'center',\n        verticalalignment = 'center',\n        fontsize = 18,\n        fontweight='bold',\n        fontfamily='serif',\n        color='#000000')\nax8.spines[\"bottom\"].set_visible(False)\nax8.set_xticklabels([])\nax8.set_yticklabels([])\nax8.tick_params(left=False, bottom=False)\n\n# Oldpeak\nax9.grid(color='#000000', linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nsns.kdeplot(ax=ax9, data=df, x='oldpeak',hue=\"output\", fill=True,palette=[\"#8000ff\",\"#da8829\"], alpha=.5, linewidth=0)\nax9.set_xlabel(\"\")\nax9.set_ylabel(\"\")\n\nfor i in [\"top\",\"left\",\"right\"]:\n    ax0.spines[i].set_visible(False)\n    ax1.spines[i].set_visible(False)\n    ax2.spines[i].set_visible(False)\n    ax3.spines[i].set_visible(False)\n    ax4.spines[i].set_visible(False)\n    ax5.spines[i].set_visible(False)\n    ax6.spines[i].set_visible(False)\n    ax7.spines[i].set_visible(False)\n    ax8.spines[i].set_visible(False)\n    ax9.spines[i].set_visible(False)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:54:23.631561Z","iopub.execute_input":"2022-08-30T20:54:23.632741Z","iopub.status.idle":"2022-08-30T20:54:25.336283Z","shell.execute_reply.started":"2022-08-30T20:54:23.632692Z","shell.execute_reply":"2022-08-30T20:54:25.335093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explode = [0, 0.1]\nplt.figure(1, figsize=(5,5))\nplt.title(\"Distribution of likelihood of heart attack || High (1) | Low (0)\",\n          fontfamily='serif',color = \"w\", fontweight = \"bold\" , )\ndf['output'].value_counts().plot.pie(autopct=\"%1.1f%%\", explode = explode)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:54:27.597377Z","iopub.execute_input":"2022-08-30T20:54:27.597787Z","iopub.status.idle":"2022-08-30T20:54:27.745018Z","shell.execute_reply.started":"2022-08-30T20:54:27.597754Z","shell.execute_reply":"2022-08-30T20:54:27.743378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion for Exploratory Data Analysis\n1. There are no NaN values in the data.\n\n2. There are certain outliers in all the continuous features.\n\n3. The data consists of more than twice the number of people with sex = 1 than sex = 0.\n\n4. There is no apparent linear correlation between continuous variable according to the heatmap.\n\n5. The scatterplot heatmap matrix suggests that there might be some correlation between output and cp, thalachh and slp.\n\n6. It is intuitive that elder people might have higher chances of heart attack but according to the distribution plot of age with respect to output, it is evident that this isn't the case.\n\n7. According to the distribution plot of thalachh with respect to output, people with higher maximum heart rate achieved have higher chances of heart attack.\n\n8. According to the distribution plot of oldpeak with respect to output, people with lower pevious peak achieved have higher chances of heart attack.\n\nThe Distribution plot tells us the following -\n1. People with Non-Anginal chest pain, that is with cp = 2 have higher chances of heart attack.\n\n2. People with 0 major vessels, that is with caa = 0 have high chance of heart attack.\n\n3. People with sex = 1 have higher chance of heart attack.\n\n4. People with thall = 2 have much higher chance of heart attack.\n\n5. People with no exercise induced angina, that is with exng = 0 have higher chance of heart attack.","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing, Model Training and Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:54:33.342660Z","iopub.execute_input":"2022-08-30T20:54:33.343062Z","iopub.status.idle":"2022-08-30T20:54:33.687911Z","shell.execute_reply.started":"2022-08-30T20:54:33.343028Z","shell.execute_reply":"2022-08-30T20:54:33.686535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df[\"output\"]\ndf.drop(labels=target_columns, axis='columns', inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:54:34.986919Z","iopub.execute_input":"2022-08-30T20:54:34.987553Z","iopub.status.idle":"2022-08-30T20:54:34.993073Z","shell.execute_reply.started":"2022-08-30T20:54:34.987518Z","shell.execute_reply":"2022-08-30T20:54:34.992023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:20.090127Z","iopub.execute_input":"2022-08-30T20:56:20.091235Z","iopub.status.idle":"2022-08-30T20:56:20.099163Z","shell.execute_reply.started":"2022-08-30T20:56:20.091193Z","shell.execute_reply":"2022-08-30T20:56:20.098390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler(feature_range = (0,1))\nct = make_column_transformer((OneHotEncoder(), [\"sex\", \"cp\",\"fbs\", \"restecg\",\"exng\",\"slp\", \"caa\", \"thall\"]),remainder='passthrough')\n\ntransformed = ct.fit_transform(df)\ntransformed_df = pd.DataFrame(transformed, columns=ct.get_feature_names_out())\n\nX = scaler.fit_transform(transformed_df)\n# X.shape\ntransformed_df","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:24.379755Z","iopub.execute_input":"2022-08-30T20:56:24.382127Z","iopub.status.idle":"2022-08-30T20:56:24.437250Z","shell.execute_reply.started":"2022-08-30T20:56:24.382091Z","shell.execute_reply":"2022-08-30T20:56:24.436483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=101) \nX_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, train_size=0.8, random_state=42)\n\nprint(f'Total # of sample in whole dataset: {len(X)}')\nprint(f'Total # of sample in train dataset: {len(X_train)}')\nprint(f'Total # of sample in validation dataset: {len(X_valid)}')\nprint(f'Total # of sample in test dataset: {len(X_test)}')","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:26.521483Z","iopub.execute_input":"2022-08-30T20:56:26.522205Z","iopub.status.idle":"2022-08-30T20:56:26.532359Z","shell.execute_reply.started":"2022-08-30T20:56:26.522167Z","shell.execute_reply":"2022-08-30T20:56:26.531456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting the best hyperparameter for each model\nlist_i = [0.01, 0.1, 1, 10, 100]\nlist_j = [0.01, 0.1, 1, 10, 100]\nkernels = ['linear', 'poly', 'rbf', 'sigmoid']\n\nscore = 0\nbest_score = 0\nfor i in list_i:\n    for j in list_j:\n        for k in kernels:\n            model  = SVC(C=i, gamma=j, kernel = k)\n            model.fit(X_train, y_train)\n            score = model.score(X_valid, y_valid)\n            if score > best_score:\n                best_score = score\n                best_para = {\"C\":i, \"gamma\" :j, \"kernel\": k}\n\nprint(best_para)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:28.009447Z","iopub.execute_input":"2022-08-30T20:56:28.009828Z","iopub.status.idle":"2022-08-30T20:56:28.427159Z","shell.execute_reply.started":"2022-08-30T20:56:28.009798Z","shell.execute_reply":"2022-08-30T20:56:28.426320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = {}\ntrain_score = {}\ntest_score = {}\nfor i in range(1,21):\n    model = KNeighborsClassifier(n_neighbors=i)\n    model.fit(X_train, y_train)\n    score[i] = round(model.score(X_valid, y_valid) ,2)\n    train_score[i] = round(model.score(X_train, y_train), 2)\n    test_score[i] = round(model.score(X_test, y_test),2)\n\nKNscores = pd.DataFrame([score, train_score, test_score], index = [\"Validation Score\", \"Training Score\", \"Testing Score\"])\nKNscores\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:29.548371Z","iopub.execute_input":"2022-08-30T20:56:29.549078Z","iopub.status.idle":"2022-08-30T20:56:30.174648Z","shell.execute_reply.started":"2022-08-30T20:56:29.549045Z","shell.execute_reply":"2022-08-30T20:56:30.173131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training, Testing and analysis of model metrics","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:46:35.779600Z","iopub.execute_input":"2022-08-30T20:46:35.780422Z","iopub.status.idle":"2022-08-30T20:46:35.786459Z","shell.execute_reply.started":"2022-08-30T20:46:35.780367Z","shell.execute_reply":"2022-08-30T20:46:35.785246Z"}}},{"cell_type":"code","source":"models = {\n    \"DecisionTreeCLassifier\" : DecisionTreeClassifier(),\n    \"KNeighborClassifier\": KNeighborsClassifier(n_neighbors=20),\n    \"SupportVectorClassifier\": SVC(**best_para)\n    \n}\nmodel_names = list(models.keys())\n\ntrainScores = []\nvalidationScores = []\ntestScores = []\nfor m in models:\n    model = models[m]\n    print(X_train.shape, y_train.shape)\n    \n    model.fit(X_train, y_train)\n    score = model.score(X_valid, y_valid)\n  #print(f'{m} validation score => {score*100}')\n    \n    print(f'{m}') \n    train_score = model.score(X_train, y_train)\n    print(f'Train score of trained model: {train_score*100}')\n    trainScores.append(train_score*100)\n\n    validation_score = model.score(X_valid, y_valid)\n    print(f'Validation score of trained model: {validation_score*100}')\n    validationScores.append(validation_score*100)\n\n    test_score = model.score(X_test, y_test)\n    print(f'Test score of trained model: {test_score*100}')\n    testScores.append(test_score*100)\n    print(\" \")\n    \n    y_predictions = model.predict(X_test)\n    conf_matrix = confusion_matrix(y_predictions, y_test)\n\n    print(f'Confusion Matrix: \\n{conf_matrix}\\n')\n\n#     predictions = model.predict(X_test)\n#     cm = confusion_matrix(predictions, y_test)\n\n    tn = conf_matrix[0,0]\n    fp = conf_matrix[0,1]\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    accuracy  = (tp + tn) / (tp + fp + tn + fn)\n    precision = tp / (tp + fp)\n    recall    = tp / (tp + fn)\n    f1score  = 2 * precision * recall / (precision + recall)\n    specificity = tn / (tn + fp)\n    print(f'Accuracy : {accuracy}')\n    print(f'Precision: {precision}')\n    print(f'Recall   : {recall}')\n    print(f'F1 score : {f1score}')\n    print(f'Specificity : {specificity}')\n    print(\"\") \n    print(f'Classification Report: \\n{classification_report(y_predictions, y_test)}\\n')\n    print(\"\")\n    model_names.remove(model_names[0])\n\n#     preds = model.predict(X_test)\n#     confusion_matr = confusion_matrix(y_test, y_predictions) #normalize = 'true'\n    print(\"############################################################################\")\n    print(\"\")\n    print(\"\")\n    print(\"\")","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:32.919568Z","iopub.execute_input":"2022-08-30T20:56:32.920298Z","iopub.status.idle":"2022-08-30T20:56:33.026692Z","shell.execute_reply.started":"2022-08-30T20:56:32.920261Z","shell.execute_reply":"2022-08-30T20:56:33.025081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.set_style('darkgrid')\nplt.title('Train - Validation - Test Scores of Models', fontweight='bold', size = 24)\n\nbarWidth = 0.25\n \nbars1 = trainScores\nbars2 = validationScores\nbars3 = testScores\n \nr1 = np.arange(len(bars1))\nr2 = [x + barWidth for x in r1]\nr3 = [x + barWidth for x in r2]\n \nplt.bar(r1, bars1, color='red', width=barWidth, edgecolor='white', label='train', yerr=0.5,ecolor=\"black\",capsize=15)\nplt.bar(r2, bars2, color='black', width=barWidth, edgecolor='white', label='validation', yerr=0.5,ecolor=\"black\",capsize=10, alpha = 0.5)\nplt.bar(r3, bars3, color='blue', width=barWidth, edgecolor='white', label='test', yerr=0.5,ecolor=\"black\",capsize=10)\n \nmodelNames = ['DecisionTreeClassifier','KNeighborsClassifier', 'SupportVectorMachine']\n    \nplt.xlabel('Algorithms', fontweight='bold', size = 24, color = \"w\")\nplt.ylabel('Scores', fontweight='bold', size = 24)\nplt.xticks([r + barWidth for r in range(len(bars1))], modelNames, rotation = 75, fontweight = \"bold\", fontsize = 15)\n \nplt.legend(prop = {\"size\" :20})\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:34.141453Z","iopub.execute_input":"2022-08-30T20:56:34.142483Z","iopub.status.idle":"2022-08-30T20:56:34.516338Z","shell.execute_reply.started":"2022-08-30T20:56:34.142448Z","shell.execute_reply":"2022-08-30T20:56:34.515153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(modelNames)):\n    print(f'Accuracy of {modelNames[i]} -----> {testScores[i]}')","metadata":{"execution":{"iopub.status.busy":"2022-08-30T20:56:36.141531Z","iopub.execute_input":"2022-08-30T20:56:36.141933Z","iopub.status.idle":"2022-08-30T20:56:36.148623Z","shell.execute_reply.started":"2022-08-30T20:56:36.141900Z","shell.execute_reply":"2022-08-30T20:56:36.147404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion of the Classification Modelling\n\n#### It is evident that the KNeighbours Classifier with number of neighbours as 20 performs best compared to SVC (Support Vector Classifier) and Decision Tree Classifier","metadata":{}}]}